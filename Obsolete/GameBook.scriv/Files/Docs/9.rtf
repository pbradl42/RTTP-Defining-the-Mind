{\rtf1\ansi\ansicpg1252\cocoartf1265\cocoasubrtf200
{\fonttbl\f0\froman\fcharset0 TimesNewRomanPSMT;\f1\fswiss\fcharset0 ArialMT;\f2\fswiss\fcharset0 Helvetica;
}
{\colortbl;\red255\green255\blue255;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}}
\deftab709
\pard\pardeftab709

\f0\fs24 \cf0 \
\pard\pardeftab709\li283\fi-283

\b\fs32 \cf0 A Primer on Research {\field{\*\fldinst{HYPERLINK "scrivcmt://03E1046E-5C25-431C-84B0-9D02B401D04C"}}{\fldrslt Methods}}
\b0\fs20 \
\pard\pardeftab709\sa120

\fs24 \cf0 Let's start with a plausibly empirical claim\'97one that you may believe:\
\pard\pardeftab709\li283\sa120
\cf0 (A) To be educated, one must study.\
\pard\pardeftab709\sa120
\cf0 How might one investigate that claim scientifically? Notice, first of all, that it is a general claim. 'One' is a pronoun that could stand for any person, so the claim is universal in nature. We cannot claim that a universal claim like this is
\i  true
\i0  unless it is true for every person. But that is empirically impossible to verify.\
One might think, then, that claims such as (A) require
\i  a priori
\i0  conceptual analysis\'97like the methods used frequently in Philosophy or Math\'97one might argue that the concept of 'being educated' entails the concept of 'study'. Or one could argue that the negation of (A) implies a contradiction.\
The problem with these techniques, as you might imagine, is that concepts are not universally shared. One person or culture might have a slightly different concept of 'being educated' than another. And if the concepts can change, the conceptual analysis will not hold up. It follows, then, that the
\i  a priori
\i0  technique is no more universal than any other method.\
So how do we investigate a claim such as (A) empirically?\
The first step is to recognize that (A) will never be proven true. We can find evidence to support belief in (A), and we can use (A) to construct programs that help people become educated. But we cannot ever say that (A) is
\i  true
\i0  universally. Evidence adduced in favor of (A) can take many forms:\
\pard\pardeftab709\sb240\sa120

\f1\b\fs28 \cf0 Observational Research
\i \
\pard\pardeftab709\sa120

\f0\i0\b0\fs24 \cf0 Observational research seeks to observe behavior without intervening in the situation where that behavior takes place. It is, of course, an impossible ideal. The observer's presence in any situation necessarily changes the behavior that is meant to be observed. A scientific observation, then, should take significant steps to minimize the impact of the observation on the behavior being observed.\
\pard\pardeftab709\sb240\sa120

\f1\b\fs28 \cf0 Naturalistic observation\
\pard\pardeftab709\sa120

\f0\b0\fs24 \cf0 In naturalistic observation, the observer seeks to minimize his or her impact on the behavior observed by becoming a part of the situation in which the behavior occurs. In the case of (A), then, a naturalistic observer might disguise himself or herself as a college student and join a community of people seeking education. The scientist would then carefully document the ways in which people study, and their levels of education.\
\pard\pardeftab709\sb240\sa120

\f1\b\fs28 \cf0 Systematic observation\
\pard\pardeftab709\sa120

\f0\b0\fs24 \cf0 A systematic observation differs from a naturalistic observation in so far as the behaviors observed are classified according to a
\i  coding system
\i0  and counted according to their frequency or their duration. In the case of (A), you are probably wondering what it means 'to be educated' or what it means 'to study.' \'93Studying,' after all, covers reading, writing, doing problem sets, investigating online, conducting research in labs, etc. A naturalist gathering evidence for (A) would record all these behaviors as they happen in descriptive prose. A systematic observer will look only for behaviors that fit the codes he or she has previously determined count as 'studying.'\
Naturalistic observation, as a result, will catch new and novel instances of studying-behavior that systematic observation will not. Consider 'crowd-sourcing' answers to study questions on twitter. A systematic observation set up prior to twitter's invention would not be able to count this as an instance of 'studying' unless they adapted their codes, which in turn would introduce unreliability into the data. A naturalist has no such problem. On the other hand, the naturalist cannot tell you, for example how much studying is necessary for being educated. Or how individuals in the community devide their time between the different tasks of studying.\
A systematic observer has choices to make as well: do you record the amount of time a behavior occurs, or the frequency? We all know that the sheer amount of time spent studying can be misleading - is it possible to code for study-behaviors that indicate 'quality' study time from merely looking like one is studying?\
\pard\pardeftab709\sb240\sa120

\f1\b\fs28 \cf0 Case Studies\
\pard\pardeftab709\sa120

\f0\b0\fs24 \cf0 Case studies are individual cases that highlight an aspect of the research question. In the case of (A), it might be interesting to produce a case study of an individual who was educated but never studied. Or someone who studied a great deal, but never fully became educated.\
Case studies are often used to distinguish between two concepts that were previously believed to always co-occur. In the case of memory, for example, the patient named 'HM' demonstrated that declarative memory (memory of facts) can be separated from memory for {\field{\*\fldinst{HYPERLINK "scrivcmt://094519A2-14FF-4965-A44B-46A32B86507B"}}{\fldrslt skills.}} One case in which these two behaviors come apart is enough to show that the two
\i  can
\i0  come apart, and showing that two things
\i  can
\i0  come apart is enough to show that they are not the same thing.\
In the case of (A), if someone were to argue by conceptual analysis that 'studying' and 'being educated' are necessarily the same thing, a single case of someone's being educated without studying, or vice versa, would be enough to show that these two are not the same concept.\
Medicine often relies on case studies to progress, in part because of ethical restrictions on experimentation. But is very, very important to notice what case studies can and cannot show. A case study is a datum\'97a single point of data. They are useful in making distinctions (as in the last paragraph) and delineating new diseases. Charcot's work, for example, was based entirely on case studies. As was most of the early work in neurology, including Broca's famous localization of the speech area of the brain. But they are almost useless in crafting therapies for those diseases. After all, just because a treatment works in a single individual does not mean it will work in others. But showing that a single person
\i  can
\i0  get sick in this particular way shows that there is a way in which other people
\i  might
\i0  get sick.\
\pard\pardeftab709\sb240\sa120

\f1\b\fs28 \cf0 Variables
\i \
\pard\pardeftab709\sa120

\f0\i0\b0\fs24 \cf0 In order to move forward in our investigation of (A), it is then necessary to 'operationalize' what we mean by 'being educated' and 'studying.' Notice that I do not say 'define' here, as offering a definition is an attempt to capture the was in which the word is used by speakers of the language. That is not what we want to do . We want a measurable behavior that is recognizably related to the commonsense concept. Harry Harlow's work on 'love,' for example, operationalizes the pre-theoretical concept 'love' in terms of a specific set of behaviors, it does not attempt to define the concept 'love' as it is used by speakers of English.\
(A) mentions two variables: 'being educated' and 'studying', and claims that 'studying' is necessary for 'being educated.' (A) then makes a claim about a relationship of dependence between two distinct variables: 'being educated' depends on 'studying.'\
\pard\pardeftab709\sb240\sa120

\f1\b\fs28 \cf0 Independent Variables v. Dependent Variables\
\pard\pardeftab709\sa120

\f0\b0\fs24 \cf0 In the social sciences, we call the variable that putatively depends on another variable the
\i  dependent variable
\i0 . The variable that does not is called the
\i  independent variable
\i0 . This is not to claim that the independent variable does not depend on some other variable
\i \'97
\i0 'studying' may depend on economic independence, for example\'97but that is the subject of a different study.\
An empirically investigatable claim is one that posits a relationship between two variables. That relationship can take a number of forms. As mentioned before, one might think that (A) is a claim of logical necessity: i.e. that it is impossible to be educated without studying. Claims of that sort are the subject of philosophy and mathematics, and open to refutation through case studies.\
The more interesting claims for our purposes are claims that posit a causal or correlational relationship. One might read (A) as saying that\
\pard\pardeftab709\li283\sa120
\cf0 (A1) 'studying causes being educated.'\
\pard\pardeftab709\sa120
\cf0 Or that\
\pard\pardeftab709\li283\sa120
\cf0 (A2) 'studying is correlated with being educated.'\
\pard\pardeftab709\sa120
\cf0 Notice that (A1) differs from (A2) and both differ from (A) itself. This is most clear if we consider how we might falsify each. (A) is made false by a single case of an educated person who has not studied, or someone who has studied but is not educated. Falsifying (A1) is not so easy. Philosophers have debated what (A1) means for centuries, and that is the subject for a different class. There is a clear and well-defined mathematical relationship posited in (A2). When one variable is correlated with another variable, it means that one can predict, with a specified degree of certainty, the value of one variable given the other. Thus, if 'being educated' is highly correlated with 'studying', I can predict your level of education with a high level of certainty if I know your level of studying.\
But in order to establish a mathematical relationship between two variables, we need to measure the values of those variables in mathematical terms.\
\pard\pardeftab709\sb240\sa120

\f1\b\fs28 \cf0 Measuring Variables\
\pard\pardeftab709\sa120

\f0\b0\fs24 \cf0 A variable can be measured according to a number of different scales: nominal, ordinal, interval, and ratio are common.\
\pard\tx720\pardeftab709\li720\fi-360\sa120
\ls1\ilvl0
\f2 \cf0 \'95	
\f0\i Nominal scales
\i0  place entities or behaviors into discrete categories: we may choose to say that one is either 'studying' or 'not' in this case.\
\ls1\ilvl0
\f2 \'95	
\f0\i Ordinal scales
\i0  place entities on a scale: we may choose to rank people according to their level of 'education' in this case. Notice that using an ordinal scale requires that we say something about the magnitude of the intervals between entities on this scale. A rank order where a rank of '1' is the most educated person does not imply that the person ranked '5' is twice as educated as a person ranked '10'. It does imply that a person of any rank is more educated than each person with a numerically higher rank.\
\ls1\ilvl0
\f2 \'95	
\f0\i Interval scales
\i0  are ordinal scales where the magnitude of the interval between values is held constant. If we are going to measure 'studying' by the amount of time spent studying, we can use an interval scale: because the amount of time in 30 minutes is exactly \'bd that of the amount of time in 60 minutes.\
\ls1\ilvl0
\f2 \'95	
\f0\i Ratio scales
\i0  are interval scales where there is an absolute zero (unlike time, for example).\
\pard\pardeftab709\sa120
\cf0 Notice that we have not discussed yet
\i  how
\i0  these variables are measured according to these scales. Suppose that we operationalize 'study' in terms of time spent studying and measure it with the standard ordinal scale of hours and minutes. We still have to ask how we measure the value of 'study' for any given individual. We could ask that person to recall the number of hours spent in the last week. We could ask that person to keep a log of all studying activity over the next week. We could follow that person around for a week and write down the amount of time spent studying. Or we could set up a video camera at the front door of the library and record the time at which the person enters and leaves, assuming that all the time in between those events was spent studying.\
Each of these approaches would yield interesting data. If we can do the same thing with 'being educated', each variable will have quantified value which then can be compared to the other. Notice, however, that regardless of what approach one selects, one will overlook some instances of 'studying,' and maybe count behaviors that are not normally considered 'studying.'\
Naturalistic observation provides rich amount of information about a given behavior, but it is also the least easy to use as the basis for comparison between variables, people or populations. Reducing the richness of the information to some heuristic approximation of the behavior allows us to make precise comparisons between variables, peoples and populations\'97and all operationalizations are reductions of information via heuristic approximations.\
Each operationalization has its advantages and disadvantages, as you might suspect. But without it, comparisons between individuals and populations would be virtually impossible.\
\pard\pardeftab709\sb240\sa120

\f1\b\fs28 \cf0 Reliability\
\pard\pardeftab709\sa120

\f0\b0\fs24 \cf0 A measurement of a variable is 'reliable' if it consistently produces the same measurement given the presentation. Take our example of 'being educated.' There are many ways to measure the extent to which a person is educated.\
Grades, for example, are one measurement. If a grading system is reliable across subjects, then the same quality of work would receive the same grade, independently of the personality, political persuasion, etc. of the students being graded. If a grading system is consistent across professors (or teaching assistants), the same work would get the same grade in the same course taught by different professors. If a grading system is reliable across time, then the same quality of work done today would be receive the same grade as it did in previous generations. It should be obvious that many of the current controversies in higher education (grade inflation, reliance on graduate students for teaching tasks, etc.) that haunt higher education are, in many respects, issues of the reliability of grading systems.\
In any study of behavior, the reliability of a measurement becomes absolutely vital. If the study is observational in nature, the reliability of the coding system must be systematically tested throughout the course of observation. This is not only true when there are multiple observers coding the behavior, but even when there is just one\'97'coding drift' refers to the tendency of categories to extend and contract over the course of a study.\
\pard\pardeftab709\sb240\sa120

\f1\i\b \cf0 Measuring Reliability\
\pard\pardeftab709\sa120

\f0\i0\b0 \cf0 Suppose that two professors are teaching two sections of the same class with the same textbook and same assignments. The two sections have equal numbers of students, who were placed into the two classes randomly. The classes are large enough that any outliers either way will not effect the statistics. In such a scenario, if one of the professors gives a higher number of 'A's to the same population, it is reasonable to conclude that that professor has a different sense of what an 'A' means that the other professor. Thus, one can quickly calculate the degree of reliability between two observers by calculating the rate at which each observer assigns the different codes to the population. When reliable, we expect a 'joint probability of agreement': each observer has the same probability of assigning the codes to the given population.\
As you might expect, this measurement says nothing about which members of the population get getting what codes: the two professors may agree that their grade distribution will fit a strict curve, but they evaluate the work in completed inverted ways\'97and 'A' for one would be 'F' for the other. So long as there were only 5 'A's and 5 'F's, the professors would have a joint probability of agreement.\
In 1960, Jacob Cohen proposed a measurement in the journal E
\i ducation and Psychological Measurement.
\i0  Cohen's Kappa, as it is now known, is simply defined as:\
\pard\pardeftab709\sa120\qc
\cf0 \
\pard\pardeftab709\sa120
\cf0 Pr(a) is the observed probability of the observers agreeing, and Pr(e) is the probability of them agreeing by chance. There is, of course, a great more than can be said about calculating reliability of observation, but that will be left for future work.\
\pard\pardeftab709\sb240\sa120

\f1\i\b \cf0 Reliability of mechanisms.\
\pard\pardeftab709\sa120

\f0\i0\b0 \cf0 If the study makes use of mechanisms for measuring variables (such as a pressing a lever), the mechanism must be tested for reliable recording on a regular basis. For example, if grades are calculated automatically by a computer scoring system, for example, one must regularly verify that the system itself card-reader itself is reading the dots on the answer sheet correctly.\
The same concerns hold for self-reporting studies and surveys: over time, the way a survey is understood by the participants may change. A freshman may report his or her workload as 'heavy' in the first semester of college, but recognize by senior year that that it was actually 'light.'\
\pard\pardeftab709\sb240\sa120

\f1\b\fs28 \cf0 Experimental Interventions
\i \
\pard\pardeftab709\sa120

\f0\i0\b0\fs24 \cf0 Once we have an operational definition of our variables, we can begin to design an experiment to establish the degree of correlation between those variables.\
The first step is, of course, establishing the population to be studied. As you probably noticed, the examples in the previous section assume that the proper population to study in establishing (A) was college students. This is by no means the only population that is 'educated' or that 'studies.' Our experiment might be very different if our population was rhesus monkeys, for example. The population to be studied is often implicit in the process of operationalization, but made explicit in the experimental design.\
The basic idea of all experimental design is to measure the degree to which the dependent variable varies as a function of the independent variable. It is the responsibility of the designer, then, to rule out all other possible factors that might cause variation in the dependent variable
\i  other than
\i0  the independent variable. Let us return to (A2). Suppose we operationalize 'study' as 'amount of time spent studying in 1 week according to self-reported memory' and 'being educated' as 'self-reported confidence in one's own education on a ordinal scale of 1-7 where 1 is 'completely educated' and 7 is 'totally uneducated'.'\
To determine the extent of the dependence of 'being educated' on 'studying', we need to be able to vary 'studying' systematically and compare it to the value of 'being educated.' The easiest way to do this is to find two populations, one where the independent variable is locked (the 'control' group), and one where the independent variable is manipulated (the 'experimental' group). Let us then take a population of students and split them between two groups. One is instructed to study normally for a week, and the other instructed to study twice as much as normal. Then we ask each group to measure their levels of 'education,' and compare the results.\
It is plausible that students at Ivy League colleges may overestimate their level of education if asked to compare themselves to students at large state universities. The social-cultural bias implicit in our notion of 'being educated' is a confound in this experiment. In order to truly control it, we would have to operationalize 'being educated' in some way other than self-evaluation. Suppose we operationalize 'being educated' as 'scores on a test of literary allusions taken from the Norton Anthology of Literature.'\
Now suppose that our groups just happened to result in only English majors in one and Math majors in the other. The results of the 'education' measure will plausibly be skewed in some important way. We then must require that the population be randomly selected and assigned to the two groups. These are standard techniques for controlling confounding variables.\
\pard\pardeftab709\sb240\sa120

\f1\b\fs28 \cf0 Internal and External Validity\
\pard\pardeftab709\sa120

\f0\b0\fs24 \cf0 When all possible confounds are dealt with and the results of an experiment can plausibly be said to show a dependence of the dependent variable on the independent variable, we can call that experiment
\i  internally valid
\i0 . When the variables are operationalized in such a way that the experiment shows a relationship between the pre-theoretical concepts used by normal speakers of the language, we can call that experiment
\i  externally valid
\i0 .\
\pard\pardeftab709\sb240\sa120

\f1\b\fs28 \cf0 Common controls\
\pard\pardeftab709\sa120

\f0\b0\fs24 \cf0 As mentioned above, any variable that effects the dependent variable which is not controlled by the experiment is called a
\i  confounding variable
\i0 . Simple experiments seek to control any confounding variables by blocking their effects on the dependent variable or eliminating them from experimental design altogether.\
The simplest way to do this is to create two groups of participants, one of which will receive the experimental intervention and one of which will not: the experimental group and the control group. If the groups are somehow systematically different, however, that would introduce a new confound into the experiment. Thus, the first common control is
\i  random assignment
\i0 .\
Even if the groups are randomly chosen from an existing population, one must consider from what community the participants were recruited. Most psychological studies historically have been performed on college students. This population does not mirror the general population in a number of important ways: they tend to be relatively affluent, intelligent and familiar with scientific thinking. Recruiting participants in a study because they are statistical outliers on some variable introduces the problem of
\i  regression to the mean.
\i0  People who perform extraordinarily well on a given task will tend, over time, to track back toward average. If one recruits participants for a study from the high-achieving group, it is very likely that they will see a reduction in that achievement over time. On the flip side, low-achieving people will tend to increase just because they will tend towards the average.\
Evelyn Hooker's famous study of mental health of homosexuals, for example, was notable in that it recruited participants from the community, rather that from the the existing clientele of mental health practitioners. She contended that previous studies that had found a correlation between homosexuality and poor mental health had failed this rather obvious control.\
Case studies, by their very nature, do not have a control group. One might argue that case studies always build off the common population for their control group, but without explicitly addressing that as the control, one is right to worry about the extent to which case studies can be extrapolated.\
\pard\pardeftab709\sb240\sa120

\f1\b\fs28 \cf0 Simple experimental designs\
\pard\pardeftab709\sa120

\f0\b0\fs24 \cf0 Experimental design is, at its most basic, about setting up was to compare individuals who have had the experimental intervention with those that have not.\
\pard\pardeftab709\sb240\sa120

\f1\b \cf0 Between groups with control
\i \
\pard\pardeftab709\sa120

\f0\i0\b0 \cf0 The simplest experimental design randomly assigns participants into one of two groups, administrates the experimental intervention to the one of the groups, and measures the dependent variable in both groups and compares the results. Of course, one would have to make sure that the two groups were pulled from a population representative of the college as a whole.\
If we return to our example of 'studying is correlated with being educated', there are a couple of ways in which this would work: students would be assigned randomly to one of two groups. One of the groups would be instructed to study more than usual, and the other left to do what they normally did. After some period of time, their rate of education would be measured (how it is operationalized and measured is a different topic). If 'time spent studying' is positively correlated with 'being educated', we'd see an increase in the dependent variable in the experimental group.\
Alternatively, one could require that the experimental group study
\i  less
\i0  than than normal. If the correlation exists, one would see a decrease in the experimental group's rate of education\'97but that would still help establish the positive correlation between the two variables.\
It is possible for 'time spent studying' to be negatively correlated with 'being educated.' If that were the case, the experimental intervention of 'more study' would produce a decrease in 'being educated,' and the experimental intervention of 'less study' would produce an increase in 'being educated.'\
\pard\pardeftab709\sb240\sa120

\f1\b \cf0 One-group pre-test / post-test
\i \
\pard\pardeftab709\sa120

\f0\i0\b0 \cf0 In a pre-test / post-test experiment, the variable in question is measured both before and after the experimental intervention. In this case, a single group is compared to itself. Returning to our example of 'being educated', we might test first year students during orientation on a crucial skill like 'Critical Thinking', and then again at graduation, in order to determine the extent to which the college experience developed the students' education.\
Of course, there are many worries here. The first, and most obvious, of which is the
\i  maturation effect
\i0 . People mature a great deal between the ages of 18 and 21, regardless of whether or not they are in college. Measuring critical thinking skills in a simple pre-test / post-test design would not be able to distinguish between the development that was due to simple maturation, and that which was due to being in college.\
Second, college is not just about what happens in the classroom: it is about the environment of the college as a whole. The
\i  history
\i0  of the participants that is not a part of the experimental intervention may confound the study.\
Third, standard tests, while they increase reliability, can also increase the skills of the participants themselves. Taking tests of critical thinking skills can, itself, increase one's critical thinking skills. Thus, if the pre-test and post-test are given in a short space of time, the
\i  testing
\i0  itself could confound the experiment.\
 Fourth, the way in which we measure may be subject to
\i  instrument decay
\i0 . If students in high school, for example, get annoyed by standardized testing, they may express this annoyance by not making their best effort on the test\'97I've heard many anecdotes over the years that students are increasingly 'voicing' their opposition to the current emphasis on standardized testing by randomly filling in the answer sheet and turning it in.\
\pard\pardeftab709\sb240\sa120

\f1\b \cf0 Matched subjects
\i \
\pard\pardeftab709\sa120

\f0\i0\b0 \cf0 I'm sure that at this point, you're all pretty skeptical about the ability of my hypothetical experiments to test the correlation between studying and being educated. I'm sure of this because like most college students, you probably believe that being educated is profoundly effected by a students natural aptitude for education. \'93Some people,\'94 you'll likely argue, \'93are just better at X than others\'97if one of your groups just happened to have a higher population of people who are at X than the other, and you measure 'education' in terms of 'X', there will be a problem.\'94 We get around this problem by using a
\i  matched random assignment
\i0  experimental design.\
Suppose that I decided to measure 'being educated' in terms of verbal analogies\'97like the SAT test does. Some students plausibly are better at vocabulary than others. If my experimental group had a higher population of, say, people who took Latin in high school, it is likely that my groups would differ in terms of their verbal analogies score without any experimental intervention at all, or the experimental group would respond better to the experimental intervention than the control group would have.\
In order to block this confound, we can match members of the two groups in terms of their verbal analogy ability. For every high-achieving member of the experimental group, there is a high-achieving member of the control group, and likewise for low-achieving groups. Thus, the average scores of the two groups, without experimental intervention, should be identical.\
This design, while innovative, is open to a major problem:
\i  mortality
\i0 . Individual participants will leave an experiment for a variety of reasons, just like students leaving college. If a participant leaves a matched-pair study, the experimenter risks losing two participants or introducing inequality in the groups. Morality is a problem for all experiments that seek to measure a variable over time, but it is particularly acute for matched-pair experiments.\
\pard\pardeftab709\sb240\sa120

\f1\b\fs28 \cf0 Modeling and abductive {\field{\*\fldinst{HYPERLINK "scrivcmt://BB5E867A-0547-49CA-A5A4-92BC74B33971"}}{\fldrslt reasoning}}
\i \
\pard\pardeftab709\sa120

\f0\i0\b0\fs24 \cf0 When asked what he would have done if Sir Arthur Eddington's 1919 gravitational lensing experiment had disproved his theory of gravitation, rather than confirming it, Einstein is reported to have said:\
\pard\pardeftab709\li283\sa120
\cf0 Then I would have felt sorry for the dear Lord. The theory is correct.\
\pard\pardeftab709\sa120
\cf0 Einstein was so convinced of the veracity of his theory that a false result would not have meant that his theory was false, but rather that God had gotten it wrong! Humorous quips aside, Einstein's confidence was not born of experimental data (he did few, if any, actual experiments in his life) it was born of the beauty and elegance of his theories. These are abductive virtues: virtues of a theory that make it more attractive than its competitors, all explanatory power being equal.\
\pard\pardeftab709\sa120

\b \cf0 Abductive reasoning
\b0  is 'reasoning to the best explanation.' Unlike 'induction', which extends some observation of regularity to an unobserved population (i.e. most educated people are empathetic, therefore it is likely that the next educated person I meet is empathetic), abduction posits an explanation for the regularity observed (i.e. educated people have had experiences where they have been required to adopt another person's perspective, which is a form of empathy). Like induction, abduction is uncertain, relying on probability and predictive power, neither of which will guarantee the certainty of its results.\
The term 'abduction' was originally introduced by C.S. Peirce, friend of William James and professor at Hopkins during the early days of American Research universities. Peirce distinguished abduction from induction insofar as induction, yet believed that a true scientific method must make use of all three concurrently.\

\b Modeling
\b0  involves creating a mechanism\'97virtual or actual\'97that functions in the same way as the target phenomenon. If one wants to understand
\i  how
\i0  studying relates to being educated, one would have to create a mechanism that was capable of both studying and being educated (that, I fear, is still a long ways off).\
If I want to understand how erosion happens, I can build a small-scale environment in my sandbox and subject it to a deluge of water. If I want to know about how a cruise ship will fair in the open ocean, I can build a small-scale version of it and let it float in a wave pool. If I want to know about how moving bodies interact, I can build a system of mathematical formula that will interact in the same way. These are all
\i  models
\i0  of target phenomena. The best model is the one that best fits the phenomenon\'97the one that acts the same way in the constrained environment as the target object does in the real environment.\
Building a model, and testing its fit, usually involves three distinct investigative strategies: activating, stimulating and lesioning.\
\pard\tx720\pardeftab709\li720\fi-360\sa120
\ls2\ilvl0
\f2 \cf0 \'95	
\f0 'Activating' simply means instigating the instigating the target phenomenon, and measuring the behaviors it engages in: assigning homework and then measuring studying time would be an example.\
\ls2\ilvl0
\f2 \'95	
\f0 'Stimulating' means to intervene in the underlying parts: for example, we could provide specific neurologically-active chemicals, such as caffeine, to studiers and measure neural activity during the process.\
\ls2\ilvl0
\f2 \'95	
\f0 Finally, 'lesioning' means cutting some part of the mechanism out. In psychology, for obvious ethical reasons, lesioning happens only by accident. But that doesn't mean that it doesn't occur: Broca's study of 'Tam', Scoville & Milner's study of 'HM' and Tulving's study of 'KC' are all cases of lesioning.\
\pard\pardeftab709\sa120
\cf0 Modeling is not a investigative strategy that is in competition with experimentation. Modeling and experimentation complete each other, as scientists experiment on models, and they build models to replicate the behaviors of the target organism that were discovered via experimentation.\
Consider for a moment natural language. As Chomsky pointed out, the set of utterable grammatical sentences in a natural language is infinite. An adequate explanation for our grammatical abilities, then, requires a model of how this set of sentences are generated. Simply describing the set of possibly grammatical sentences is not enough to explain how it is that our minds recognize some as acceptable and some as unacceptable. At least, that is the Cognitivists' contention.\
\pard\pardeftab709\sb240\sa120

\f1\i\b \cf0 Abductive Virtue\
\pard\pardeftab709\sa120

\f0\i0\b0 \cf0 The virtues of a theory that makes it attractive (or the 'best' explanation available) are often pragmatic in nature; and, as philosophers of science are fond of pointing out, often have more to sociocultural values than the facts intrinsic to science. We have already encountered the most famous virtue of abduction:\
\pard\pardeftab709\sa120

\b \cf0 Simplicity:
\b0  Often called 'Occum's razor', after William of Occum; although no one is sure if he ever actually held any of the views he is now identified with, simplicity can be summarized thus:\
\pard\pardeftab709\li283\sa120
\cf0 All other things being equal, the simplest explanation is probably correct.\
\pard\pardeftab709\sa120
\cf0 This is a classic abductive virtue. It doesn't say that simple explanations are
\i  always
\i0  correct. It says that a simple explanation is to be preferred to a complicated explanation
\i  when they are equal with respect to explanatory power.
\i0  If I try to explain the breaking of a glass in terms of pixies and wars, my theory can only be a contender if I can explain the breaking of all glasses, AND the rare occasions in which glasses don't break. If I can't do that, then my theory is a non-starter.\
\pard\pardeftab709\sa120

\b \cf0 Precision
\b0 . Typified by our preference for quantified theories rather than qualitative theories, a theory that can make precise predictions is preferred to a theory that makes only vague or 'fuzzy' predictions.\

\b Clarity
\b0 . My advisor used to tell me "if you can't state your theory without cracking a smirk, you don't really believe it" That is about right. In order to move a theory forward, one has to be able to explain it easily to others, and a clear theory is more easily explainable than an opaque theory.\

\b Consistency
\b0 . A basic criteria of the acceptability of a theory is its internal coherence. A virtue of a good theory is its consistency with other theories of the day.\

\b Unity
\b0 . A single theory that can explain multiple phenomena is better than an ad hoc theory that explains only one phenomenon. This is, interestingly, the driving force for choosing theories in modern theoretical physics. The opposite of 'unity' is 'ad hoc' explanations. If a suggested model explains
\i  only
\i0  the phenomenon it is supposed to explain and suggests no further course of research, it is ad hoc. For example, if I were to explain why a particular patient was depressed in terms of that person's having a special tendency to be depressed, my explanation is
\i  ad hoc
\i0 .\

\b Elegance
\b0 . What counts as 'elegance' in a theory varies from discipline to discipline, and even researcher to researcher. It is hard to describe exactly what makes a theory elegant, but it is something like having all of the virtues listed here in the right balance.\
\
\
}